---
title: "South Africa's Exports and Imports Unit Value Indices"
author: 'James Matosse'
format: 'html'
---

# Introduction

Analysis of the South Africa's exports and imports behaviours with the data gathered by Stats SA. The purpose of the analysis is showcase the skills acquired through courses and training I've been involved with and/or privy to attend over the last two years. The Stats SA statisitcal release P0142.7 will be used as guideline for key figures and analytical series.

## Load the sheet content to inspect its structure

The downloaded data is in an excel spreadsheet and ranges from 2016 to August 2024.

```{python}
import pandas as pd
import plotly.express as px
import numpy as np
import plotly.graph_objects as go

import warnings
warnings.filterwarnings("ignore")

data = pd.read_excel('data/Export and Import Unit Value Indices 2016 to 2024.xlsx', sheet_name='Export and Import Unit Value In')
data
```

The read data has 67 rows and 112 columns, it is cleary a wide dataset.

# Data cleaning

First, melt the wide data to easily perform data analysis. Columns H01, H02, H17, H18 and H25 can be removed. The observations were collected on a monthly bases. The December 2020 was used as the baseline for all the observations.

```{python}
data_long = data.melt(id_vars=['H01', 'H02', 'H03', 'H04', 'H05', 'H17', 'H18', 'H25'], var_name='Date', value_name='Amount')
clean_data = data_long.drop(columns=['H01', 'H02','H17', 'H18', 'H25'])
clean_data
```

Reduce the categories 

## Plot the data

The clean_data is now a long dataset with 6968 rows and 5 columns; the "Date" column contains the month and year for each observation. But the "Date" needs to be cleaned further for timeseries analysis, which will be done later. For now, let's plot the "Amount", "H04" and "H05" columns and draw some interprentations.

```{python}

px.histogram(clean_data, y='H04', x='Amount', color='H04', title= "South Africa's Exports and Imports Summary",)
```

The bar plot above indicate that the imports exceeds the exports by 50k of the unit value. Now, let's look at the subcategories for each imports and exports.

```{python}
# Truncate function
def truncate_label(label, max_length=10):
    return label[:max_length] + "..." if len(label) > max_length else label

# Apply truncation to the `H05` column
clean_data['H05_truncated'] = clean_data['H05'].apply(lambda x: truncate_label(x, max_length=25))

print(clean_data)

# Create the histogram
fig = px.histogram(
    clean_data.query('H04 == "Imports"'), 
    y='H05_truncated', 
    x='Amount',
    barmode='relative',
)

# Update layout for better readability
fig.update_layout(
    yaxis_title="Imports categories",
    xaxis_title="Sum of Amount",
    title="South African Imports for the 8 Years Period"
)

# Show the plot
fig.show()

```

```{python}
fig1 = px.histogram(clean_data.query('H04 == "Exports"'), y='H05_truncated', x='Amount')

# Update layout for better readability
fig1.update_layout(
    yaxis_title="Exports categories",
    xaxis_title="Sum of Amount",
    title="South African Exports for the 8 Years Period"
)

# Show the plot
fig1.show()
```

Other transportable goods is the highest category imported with a sum of 21.5k of unit value followed by crude petroleum at 14.4k of unit value. Whilst coal on the other hand is the highest category exported with a sum of 15.4k unit value, followed by coke oven at 12.8k unit value.

## Timeseries analysis

For time series, extract the month and year from the date column and convert to datetime variable. Then we plot a line graph for All items subcategory.

```{python}
# Extract month and year, and convert to datetime
clean_data['datetime'] = pd.to_datetime(clean_data['Date'].str[2:], format='%m%Y')
clean_data.query('H05_truncated == "All items"')
```

```{python}
px.line(
    clean_data.query('H04 == "Imports"'),
    x="datetime",
    y="Amount",
    color="H05_truncated",
)
```

```{python}
px.line(clean_data.query('H04 == "Exports"'), x='datetime', y='Amount', color='H05_truncated')
```

# Statistical Release

## Table A - Key figures

```{python}
tabA = data.loc[((data['H05'] == 'Exports') | (data['H05'] == 'Imports')), ['H05', 'MO082023', 'MO072024', 'MO082024']]

tabA = tabA.rename(columns={'H05': 'Product', 'MO082023': 'Aug 2023', 'MO072024': 'Jul 2024', 'MO082024': 'Aug 2024'})

tabA['Aug 2024 vs. Jul 2024'] = (((tabA['Aug 2024'] - tabA['Jul 2024']) / tabA['Jul 2024']) * 100).round(2).astype(str) + "%"

tabA['Aug 2024 vs. Aug 2023'] = (((tabA['Aug 2024'] - tabA['Aug 2023']) / tabA['Aug 2023']) * 100).round(2).astype(str) + "%"

tabA
```

## Table B - Analytical series

```{python}
data[data['H05'].isin(["Imports excluding crude", "Imports excluding crude pertroleum"])] # dataframe does not Imports excluding crude pertroleum as per P0142.7

tabB = data.loc[((data['H05'] == 'Exports excluding gold') | (data['H05'] == 'Exports excluding ores and minerals') | (data['H05'] == 'Exports excluding basic metals') | (data['H05'] == 'Imports excluding crude')), ['H05', 'H18', 'MO082023', 'MO072024', 'MO082024']]

tabB = tabB.rename(columns={'H05': 'Product', 'MO082023': 'Aug 2023', 'MO072024': 'Jul 2024', 'MO082024': 'Aug 2024'})

tabB['Aug 2024 vs. Jul 2024'] = (((tabB['Aug 2024'] - tabB['Jul 2024']) / tabB['Jul 2024']) * 100).round(2).astype(str) + "%"

tabB['Aug 2024 vs. Aug 2023'] = (((tabB['Aug 2024'] - tabB['Aug 2023']) / tabB['Aug 2023']) * 100).round(2).astype(str) + "%"

tabB
```

## Export and import unit value indices

```{python}
color_scheme = {"Exports": '#6595a8', 'Imports': '#42c2f5'}

fig_line = px.line(
    clean_data.query('H05 == "Imports" | H05 == "Exports"'),
    x="datetime",
    y="Amount",
    color="H05",
    labels={'H05': "", 'Amount': 'Index', 'datetime': 'Period'},
    color_discrete_map=color_scheme, 
    line_dash='H05', 
    title='Export and Import Unit Value Indices: January 2016 - August 2024'
).update_layout(
    yaxis_title= 'Index',
    xaxis_title= "",
    legend=dict(
        orientation="h",  # Horizontal orientation
        yanchor="top",  # Anchor at the top of the legend box
        y=-0.2,  # Position it below the plot (adjust as needed)
        xanchor="center",  # Center align the legend
        x=0.5,  # Place at the center of the plot horizontally
    ),
)
fig_line.show()

```

## Export UVI rates of change (%)

Annual rate of change is calculated as ((Aug 2024 - Aug 2023)/ Aug 2023) * 100

```{python}
# Prepare categories and an empty dictionary to store figures
cats = ["Exports", "Imports"]
figures = {}  # Dictionary to store figures

for cat in cats:
    exports_data = clean_data.query("H05 == @cat")
    # Extract the month from the datetime column (since it contains date strings like 'YYYY-MM-dd')
    exports_data["Month"] = pd.to_datetime(exports_data["datetime"]).dt.month_name()
    #    return exports_data

    # Calculate the monthly rate of change
    exports_data["Monthly change (%)"] = exports_data["Amount"].pct_change() * 100

    exports_data["Year"] = pd.to_datetime(exports_data["datetime"]).dt.year

    exports_data["Annual mean"] = exports_data.groupby("Year")["Amount"].transform(
        "mean"
    )

    # Ensure the data is sorted by month number
    exports_data["Month_Num"] = pd.to_datetime(exports_data["datetime"]).dt.month
    exports_data = exports_data.sort_values(by=["Month_Num", "Year"])

    # Calculate the annual change for each month
    exports_data["Annual Change (%)"] = (
        exports_data.groupby(["Month_Num"])["Amount"].pct_change(periods=1) * 100
    )

    # Re-sort the data
    exports_data = exports_data.sort_values(by=["datetime"]).query(
        'datetime >= "2017-01-01"'
    )  # to remove the NaNs from 2016 annual change

    # Create the figure
    figE_bar_line = go.Figure()

    # Add bar plot for 'monthly rate' vs. 'datetime' (y-axis 1)

    figE_bar_line.add_trace(
        go.Bar(
            x=exports_data["datetime"],
            y=exports_data["Monthly change (%)"],
            name=f"Monthly rate",
            marker=dict(color=color_scheme[cat]),  # Assign color
        )
    )

    # Add a secondary y-axis for 'annual rate' (y-axis 2)

    figE_bar_line.add_trace(
        go.Scatter(
            x=exports_data["datetime"],
            y=exports_data["Annual Change (%)"],
            mode="lines",
            name=f"Annual rate",
            yaxis="y2",
            showlegend=True,
            line=dict(color="#646970"),  # Assign matching color
        )
    )

    # Update layout to include a second y-axis
    figE_bar_line.update_layout(
        title=f"{cat} UVI rates of change (%) from 2017 to 2024",
        xaxis=dict(
            title="",
            #            gridcolor="#cccccc",  # Light gray for horizontal gridlines,
            #        linecolor="#333333",  # Dark gray for the secondary y-axis line
            #        linewidth=2,
            #        tickcolor="#555555",
            # Thickness of the x-axis line
            #        ticks="outside",      # Display ticks outside the axis line
            #        tickwidth=2,          # Width of the ticks
            #        tickcolor="#333333",
        ),
        yaxis=dict(
            title="Monthly rate",
            side="left",
            #            gridcolor="#cccccc",
            #            linecolor="#555555",  # Dark gray for the secondary y-axis line
            #            linewidth=2,
            #        tickcolor="#555555"
        ),
        yaxis2=dict(
            title="Annual rate",
            overlaying="y",
            side="right",
            showgrid=False,
            #            gridcolor="#cccccc",
            #            linecolor="#333333",  # Dark gray for the secondary y-axis line
            #            linewidth=2,
        ),
        legend=dict(
            orientation="h",  # Horizontal orientation
            yanchor="top",  # Anchor at the top of the legend box
            y=-0.1,  # Position it below the plot (adjust as needed)
            xanchor="center",  # Center align the legend
            x=0.5,  # Place at the center of the plot horizontally
        ),
        #        plot_bgcolor="#ffffff",  # Light gray background for the plot area #f9f9f9
        #        paper_bgcolor="#ffffff", # Slightly darker gray for the entire figure
    )

    # Show the figure
    #    figE_bar_line.show()

    # Store the figure in the dictionary
    figures[cat] = figE_bar_line

# Access the first figure (e.g., for "Exports")
exports_figure = figures["Exports"]
imports_figure = figures["Imports"]
exports_figure.show()
imports_figure.show()
```


```{python}
# # import pandas as pd
# from tabulate import tabulate

# # Sample larger DataFrame
# data1 = {
#     "Category": [
#         "Fruits",
#         "Fruits",
#         "Fruits",
#         "Vegetables",
#         "Vegetables",
#         "Vegetables",
#     ],
#     "Subcategory": ["Citrus", "Citrus", "Berries", "Root", "Leafy", "Root"],
#     "Item": ["Orange", "Lemon", "Strawberry", "Carrot", "Spinach", "Potato"],
#     "Value": [10, 15, 20, 8, 12, 5],
# }
# df = pd.DataFrame(data1)

# # Initialize an empty DataFrame for cascading table
# cascading_table = pd.DataFrame(columns=["Category", "Subcategory", "Item", "Value"])

# # Slice data by Category and append it incrementally
# for category in df["Category"].unique():
#     # Add a row for the category
#     category_row = pd.DataFrame(
#         [{"Category": category, "Subcategory": "", "Item": "", "Value": ""}]
#     )
#     cascading_table = pd.concat([cascading_table, category_row], ignore_index=True)

#     # Filter data for the current category
#     category_data = df[df["Category"] == category]

#     for subcategory in category_data["Subcategory"].unique():
#         # Filter data for the current subcategory
#         subcategory_data = category_data[category_data["Subcategory"] == subcategory]

#         for _, row in subcategory_data.iterrows():
#             subcategory_row = pd.DataFrame(
#                 [
#                     {
#                         "Category": "",
#                         "Subcategory": f"  {subcategory}",  # Indent subcategory
#                         "Item": f"    {row['Item']}",  # Indent item
#                         "Value": row["Value"],
#                     }
#                 ]
#             )
#             cascading_table = pd.concat(
#                 [cascading_table, subcategory_row], ignore_index=True
#             )

# # Print the cascading table
# print(tabulate(cascading_table, headers="keys", tablefmt="grid"))
    
```

```{python}
tabE = data.query('H04 == "Exports"')
tab1 = tabE.loc[
    (
        (tabE["H05"] == "All items")
        | (tabE["H05"] == "Agriculture")
        | (tabE["H05"] == "Ores and minerals")
    ),
    ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
]

tab2 = tabE.loc[
    (
        (tabE["H05"] == "Coal")
        | (tabE["H05"] == "Metal ores")
    ),
    ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
]
tab2 = tab2.rename(columns={"H02": "H05", "H05": "H02"}) # This ensures that pd.concat does not re-order the columns

tab3 = tabE.loc[
    (
        (tabE["H05"] == "Iron ores and concentrates")
        | (tabE["H05"] == "Non-ferrous metal ores and concentrates")
    ),
    ["H02", "H04", "H05", "MO012022", "MO122022", "MO012023"],
]
tab3 = tab3.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})

tab4 = tabE.loc[
    (
        (tabE["H05"] == "Beverages")
        | (tabE["H05"] == "Other transportable goods, except metal products, machinery and equipment")
    ),
    ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
]

tab5 = tabE.loc[
    (
        (tabE["H05"] == "Coke oven and refined petroleum products")
        | (tabE["H05"] == "Basic chemicals")
        | (tabE["H05"] == "Other chemical products")
        | (tabE["H05"] == "Rubber and plastic products")
    ),
    ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
]
tab5 = tab5.rename(columns={"H02": "H05", "H05": "H02"})

tab6 = tabE.loc[
    (
        (tabE["H05"] == "Metal products, machinery and equipment")
    ),
    ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
]

tab7 = tabE.loc[
    (
        (tabE["H05"] == "Basic metals")
    ),
    ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
]
tab7 = tab7.rename(columns={"H02": "H05", "H05": "H02"})

tab8 = tabE.loc[
    (
        (tabE["H05"] == "Basic iron and steel")
        | (tabE["H05"] == "Productsof iron and steel")
        | (tabE["H05"] == "Basic precious metals and metals clad with precious metals")
        | (tabE["H05"] == "Other semi-finished metal products")
    ),
    ["H02", "H04", "H05", "MO012022", "MO122022", "MO012023"],
]
tab8 = tab8.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})

tab9 = tabE.loc[
    (
        (tabE["H05"] == "Fabricated metal products, except machinery and equipment")
        | (tabE["H05"] == "General purpose machinery")
        | (tabE["H05"] == "Special-purpose machinery")
        | (tabE["H05"] == "Transport equipment")
        | (tabE["H05"] == "Motor vehicles")
        | (tabE["H05"] == "Other  machinery and equipment") # double spacing between Other  machinery inherited from raw data
    ),
    ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
]
tab9 = tab9.rename(columns={"H02": "H05", "H05": "H02"})

# pd.concat([tab1, tab2], ignore_index=False)
```


```{python}
tables = [tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9]

# Initialize an empty DataFrame for cascading table
cascad_table = pd.DataFrame()

for table in tables:
    cascad_table = pd.concat([cascad_table, table], ignore_index=True)

cascad_table

replacements = {"Export and Import Unit Value Indices": "", "Exports": ""}

cascad_table["H05"] = cascad_table["H05"].replace(replacements)
cascad_table["H02"] = cascad_table["H02"].replace(replacements)
cascad_table["H04"] = cascad_table["H04"].replace(replacements)

cascad_table = cascad_table.rename(
    columns={
        # "H05": "",
        "H02": "Product",
        # "H04": "",
        # "H18": "Weight",
        "MO012022": "Jan 2022",
        "MO122022": "Dec 2022",
        "MO012023": "Jan 2023",
    }
)
```

```{python}
cascad_table['Jan 2023 vs. Dec 2022'] = (((cascad_table['Jan 2023'] - cascad_table['Dec 2022']) / cascad_table['Dec 2022']) * 100).round(2).astype(str) + "%"

cascad_table['Jan 2023 vs. Jan 2022'] = (((cascad_table['Jan 2023'] - cascad_table['Jan 2022']) / cascad_table['Jan 2022']) * 100).round(2).astype(str) + "%"

cascad_table
# cascad_table.iloc[1 :,0:3].value_counts(normalize=True)

```

```{python}
cascad_table.loc[~(cascad_table['Product'] == "")]  # Remove rows where all columns are empty strings

cascad_table.loc[cascad_table.iloc[:,0] != ""]
```

Calculating the weights

```{python}
exports_weight = clean_data.query('H04 == "Exports"').query(
    'datetime >= "2021-01-01" & datetime <= "2023-01-02"'
)

# Total agriculture
total_agri = (
    exports_weight.query('H05 == "Agriculture"')
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total coal
total_coal = (
    exports_weight.query('H05 == "Coal"').groupby("H05")["Amount"].sum().squeeze()
)

# Subtotal for metal ores
sub_metal_ores = (
    exports_weight.query(
        'H05 == "Iron ores and concentrates" | H05 == "Non-ferrous metal ores and concentrates"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

non_ferrous = sub_metal_ores["Non-ferrous metal ores and concentrates"]
iron_ores = sub_metal_ores["Iron ores and concentrates"]

total_metal_ores = sub_metal_ores.sum()

# Ores and minerals
total_ores = total_coal + total_metal_ores

# Total beverages
total_bev = (
    exports_weight.query('H05 == "Beverages"').groupby("H05")["Amount"].sum().squeeze()
)

# Subtotal for other transportable
sub_transportable = (
    exports_weight.query(
        'H05 == "Coke oven and refined petroleum products" | H05 == "Basic chemicals" | H05 == "Other chemical products" | H05 == "Rubber and plastic products"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total for other transportable
total_transportable = sub_transportable.sum()

# Subtotal for basic metals
sub_basic_metals = (
    exports_weight.query(
        'H05 == "Basic iron and steel" | H05 == "Productsof iron and steel" | H05 == "Basic precious metals and metals clad with precious metals" | H05 == "Other semi-finished metal products"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total for basic metals
total_basic_metals = sub_basic_metals.sum()

# Subtotal for metal products excluding basic metals
sub_other_metals = (
    exports_weight.query(
        'H05 == "Fabricated metal products, except machinery and equipment" | H05 == "General purpose machinery" | H05 == "Special-purpose machinery" | H05 == "Transport equipment" | H05 == "Motor vehicles" | H05 == "Other  machinery and equipment"'
    )  
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

total_other_metals = sub_other_metals.sum() # not on the table

total_metal_products = total_basic_metals + total_other_metals

# total exports from commodity groups
total_exports_proper = (
    total_agri + total_ores + total_bev + total_transportable + total_metal_products
)

# The weights for each commodity group
def calc_weight(comd):
    return ((comd / total_exports_proper) * 100).round(1)


weight_agri = calc_weight(total_agri)

weight_ores = calc_weight(total_ores)

weight_coal = calc_weight(total_coal)

weight_metal_ores = calc_weight(total_metal_ores)


weight_iron_ores = calc_weight(iron_ores)

weight_non_ferrous = calc_weight(non_ferrous)


weight_bev = calc_weight(total_bev)

weight_transportable = calc_weight(total_transportable)

weight_basic_chem = calc_weight(sub_transportable[0])
weight_coke = calc_weight(sub_transportable[1])
weight_other_chem = calc_weight(sub_transportable[2])
weight_rubber = calc_weight(sub_transportable[3])


weight_metal_products = calc_weight(total_metal_products)

weight_basic_metals = calc_weight(total_basic_metals)

weight_basic_iron = calc_weight(sub_basic_metals[0])
weight_precious_metals = calc_weight(sub_basic_metals[1])
weight_semi_finished = calc_weight(sub_basic_metals[2])
weight_product_iron = calc_weight(sub_basic_metals[3])


weight_fabric_metal = calc_weight(sub_other_metals[0])
weight_gen_purpose = calc_weight(sub_other_metals[1])
weight_motor = calc_weight(sub_other_metals[2])
weight_machine_equip = calc_weight(sub_other_metals[3])
weight_spec_purpose = calc_weight(sub_other_metals[4])
weight_transport = calc_weight(sub_other_metals[5])

weight_all_items = (
    weight_agri + weight_ores + weight_bev + weight_transportable + weight_metal_products
)


tb_data = {
    "Product": [
        "a1", "a2", "a3", "Coal", "Metal ores", 
        "a4", "a5", "a6", "a7", "Coke oven and refined petroleum products",
        "Basic chemicals", "Other chemical products", "Rubber and plastic products",
        "a8", "Basic metals", "a9", "a10", "a11", "a12",
        "Fabricated metal products, except machinery and equipment",
        "General purpose machinery", "Special-purpose machinery",
        "Transport equipment", "Motor vehicles", "Other  machinery and equipment"
    ],
    "Weight": [
        weight_all_items, weight_agri, weight_ores, weight_coal, weight_metal_ores, weight_iron_ores, 
        weight_non_ferrous, weight_bev, weight_transportable, weight_coke, weight_basic_chem, 
        weight_other_chem, weight_rubber, weight_metal_products, weight_basic_metals, weight_basic_iron,
        weight_product_iron, weight_precious_metals, weight_semi_finished, weight_fabric_metal, 
        weight_gen_purpose, weight_spec_purpose, weight_transport, weight_motor, weight_machine_equip
    ]
}

df_weights = pd.DataFrame(tb_data)

# Initialize a counter for the replacement values
counter = 1

# Iterate over the rows and update empty strings
for index, row in cascad_table.iterrows():
    if row["Product"] == "":
        cascad_table.at[index, "Product"] = f"a{counter}"
        counter += 1  # Increment the counter for the next replacement
    
```


```{python}
tab1_exports = pd.merge(cascad_table,df_weights, on='Product', how='left')

col_list = list(tab1_exports.columns)

col_list.insert(
    3, col_list.pop(8)
)  # Pop the 9th column (index 6) and insert at the 4th
col_list

tab1_exports = tab1_exports[col_list]

# Initialize a counter for the replacement values
countr = 1

# Iterate over the rows and update empty strings
for index, row in tab1_exports.iterrows():
    if row["Product"] == f"a{countr}":
        tab1_exports.at[index, "Product"] = ""
        countr += 1  # Increment the counter for the next replacement

tab1_exports = tab1_exports.rename(
    columns={
        "H05": "",
        "H04": "",
    }
)

tab1_exports
```