---
title: "South Africa's Exports and Imports Unit Value Indices"
author: 'James Matosse'
format: 'html'
---

# Introduction

Analysis of the South Africa's exports and imports behaviours with the data gathered by Stats SA. The purpose of the analysis is showcase the skills acquired through courses and training I've been involved with and/or privy to attend over the last two years. The Stats SA statisitcal release P0142.7 will be used as guideline for key figures and analytical series.

## Load the sheet content to inspect its structure

The downloaded data is in an excel spreadsheet and ranges from 2016 to August 2024.

```{python}
import pandas as pd
import plotly.express as px
import numpy as np
import plotly.graph_objects as go

import warnings
warnings.filterwarnings("ignore")

data = pd.read_excel('data/Export and Import Unit Value Indices 2016 to 2024.xlsx', sheet_name='Export and Import Unit Value In')
data
```

The read data has 67 rows and 112 columns, it is cleary a wide dataset.

# Data cleaning

First, melt the wide data to easily perform data analysis. Columns H01, H02, H17, H18 and H25 can be removed. The observations were collected on a monthly bases. The December 2020 was used as the baseline for all the observations.

```{python}
data_long = data.melt(id_vars=['H01', 'H02', 'H03', 'H04', 'H05', 'H17', 'H18', 'H25'], var_name='Date', value_name='Amount')
clean_data = data_long.drop(columns=['H01', 'H02','H17', 'H18', 'H25'])
clean_data
```

Reduce the categories 

## Plot the data

The clean_data is now a long dataset with 6968 rows and 5 columns; the "Date" column contains the month and year for each observation. But the "Date" needs to be cleaned further for timeseries analysis, which will be done later. For now, let's plot the "Amount", "H04" and "H05" columns and draw some interprentations.

```{python}

px.histogram(clean_data, y='H04', x='Amount', color='H04', title= "South Africa's Exports and Imports Summary",)
```

The bar plot above indicate that the imports exceeds the exports by 50k of the unit value. Now, let's look at the subcategories for each imports and exports.

```{python}
# Truncate function
def truncate_label(label, max_length=10):
    return label[:max_length] + "..." if len(label) > max_length else label

# Apply truncation to the `H05` column
clean_data['H05_truncated'] = clean_data['H05'].apply(lambda x: truncate_label(x, max_length=25))

print(clean_data)

# Create the histogram
fig = px.histogram(
    clean_data.query('H04 == "Imports"'), 
    y='H05_truncated', 
    x='Amount',
    barmode='relative',
)

# Update layout for better readability
fig.update_layout(
    yaxis_title="Imports categories",
    xaxis_title="Sum of Amount",
    title="South African Imports for the 8 Years Period"
)

# Show the plot
fig.show()

```

```{python}
fig1 = px.histogram(clean_data.query('H04 == "Exports"'), y='H05_truncated', x='Amount')

# Update layout for better readability
fig1.update_layout(
    yaxis_title="Exports categories",
    xaxis_title="Sum of Amount",
    title="South African Exports for the 8 Years Period"
)

# Show the plot
fig1.show()
```

Other transportable goods is the highest category imported with a sum of 21.5k of unit value followed by crude petroleum at 14.4k of unit value. Whilst coal on the other hand is the highest category exported with a sum of 15.4k unit value, followed by coke oven at 12.8k unit value.

## Timeseries analysis

For time series, extract the month and year from the date column and convert to datetime variable. Then we plot a line graph for All items subcategory.

```{python}
# Extract month and year, and convert to datetime
clean_data['datetime'] = pd.to_datetime(clean_data['Date'].str[2:], format='%m%Y')
clean_data.query('H05_truncated == "All items"')
```

```{python}
px.line(
    clean_data.query('H04 == "Imports"'),
    x="datetime",
    y="Amount",
    color="H05_truncated",
)
```

```{python}
px.line(clean_data.query('H04 == "Exports"'), x='datetime', y='Amount', color='H05_truncated')
```

# Statistical Release

## Table A - Key figures

```{python}
tabA = data.loc[((data['H05'] == 'Exports') | (data['H05'] == 'Imports')), ['H05', 'MO082023', 'MO072024', 'MO082024']]

tabA = tabA.rename(columns={'H05': 'Product', 'MO082023': 'Aug 2023', 'MO072024': 'Jul 2024', 'MO082024': 'Aug 2024'})

tabA['Aug 2024 vs. Jul 2024'] = (((tabA['Aug 2024'] - tabA['Jul 2024']) / tabA['Jul 2024']) * 100).round(2).astype(str) + "%"

tabA['Aug 2024 vs. Aug 2023'] = (((tabA['Aug 2024'] - tabA['Aug 2023']) / tabA['Aug 2023']) * 100).round(2).astype(str) + "%"

tabA
```

## Table B - Analytical series

```{python}
data[data['H05'].isin(["Imports excluding crude", "Imports excluding crude pertroleum"])] # dataframe does not Imports excluding crude pertroleum as per P0142.7

tabB = data.loc[((data['H05'] == 'Exports excluding gold') | (data['H05'] == 'Exports excluding ores and minerals') | (data['H05'] == 'Exports excluding basic metals') | (data['H05'] == 'Imports excluding crude')), ['H05', 'H18', 'MO082023', 'MO072024', 'MO082024']]

tabB = tabB.rename(columns={'H05': 'Product', 'MO082023': 'Aug 2023', 'MO072024': 'Jul 2024', 'MO082024': 'Aug 2024'})

tabB['Aug 2024 vs. Jul 2024'] = (((tabB['Aug 2024'] - tabB['Jul 2024']) / tabB['Jul 2024']) * 100).round(2).astype(str) + "%"

tabB['Aug 2024 vs. Aug 2023'] = (((tabB['Aug 2024'] - tabB['Aug 2023']) / tabB['Aug 2023']) * 100).round(2).astype(str) + "%"

tabB
```

## Export and import unit value indices

```{python}
color_scheme = {"Exports": '#6595a8', 'Imports': '#42c2f5'}

fig_line = px.line(
    clean_data.query('H05 == "Imports" | H05 == "Exports"'),
    x="datetime",
    y="Amount",
    color="H05",
    labels={'H05': "", 'Amount': 'Index', 'datetime': 'Period'},
    color_discrete_map=color_scheme, 
    line_dash='H05', 
    title='Export and Import Unit Value Indices: January 2016 - August 2024'
).update_layout(
    yaxis_title= 'Index',
    xaxis_title= "",
    legend=dict(
        orientation="h",  # Horizontal orientation
        yanchor="top",  # Anchor at the top of the legend box
        y=-0.2,  # Position it below the plot (adjust as needed)
        xanchor="center",  # Center align the legend
        x=0.5,  # Place at the center of the plot horizontally
    ),
)
fig_line.show()

```

## Export UVI rates of change (%)

Annual rate of change is calculated as ((Aug 2024 - Aug 2023)/ Aug 2023) * 100

```{python}
# Prepare categories and an empty dictionary to store figures
cats = ["Exports", "Imports"]
figures = {}  # Dictionary to store figures

for cat in cats:
    exports_data = clean_data.query("H05 == @cat")
    # Extract the month from the datetime column (since it contains date strings like 'YYYY-MM-dd')
    exports_data["Month"] = pd.to_datetime(exports_data["datetime"]).dt.month_name()
    #    return exports_data

    # Calculate the monthly rate of change
    exports_data["Monthly change (%)"] = exports_data["Amount"].pct_change() * 100

    exports_data["Year"] = pd.to_datetime(exports_data["datetime"]).dt.year

    exports_data["Annual mean"] = exports_data.groupby("Year")["Amount"].transform(
        "mean"
    )

    # Ensure the data is sorted by month number
    exports_data["Month_Num"] = pd.to_datetime(exports_data["datetime"]).dt.month
    exports_data = exports_data.sort_values(by=["Month_Num", "Year"])

    # Calculate the annual change for each month
    exports_data["Annual Change (%)"] = (
        exports_data.groupby(["Month_Num"])["Amount"].pct_change(periods=1) * 100
    )

    # Re-sort the data
    exports_data = exports_data.sort_values(by=["datetime"]).query(
        'datetime >= "2017-01-01"'
    )  # to remove the NaNs from 2016 annual change

    # Create the figure
    figE_bar_line = go.Figure()

    # Add bar plot for 'monthly rate' vs. 'datetime' (y-axis 1)

    figE_bar_line.add_trace(
        go.Bar(
            x=exports_data["datetime"],
            y=exports_data["Monthly change (%)"],
            name=f"Monthly rate",
            marker=dict(color=color_scheme[cat]),  # Assign color
        )
    )

    # Add a secondary y-axis for 'annual rate' (y-axis 2)

    figE_bar_line.add_trace(
        go.Scatter(
            x=exports_data["datetime"],
            y=exports_data["Annual Change (%)"],
            mode="lines",
            name=f"Annual rate",
            yaxis="y2",
            showlegend=True,
            line=dict(color="#646970"),  # Assign matching color
        )
    )

    # Update layout to include a second y-axis
    figE_bar_line.update_layout(
        title=f"{cat} UVI rates of change (%) from 2017 to 2024",
        xaxis=dict(
            title="",
            #            gridcolor="#cccccc",  # Light gray for horizontal gridlines,
            #        linecolor="#333333",  # Dark gray for the secondary y-axis line
            #        linewidth=2,
            #        tickcolor="#555555",
            # Thickness of the x-axis line
            #        ticks="outside",      # Display ticks outside the axis line
            #        tickwidth=2,          # Width of the ticks
            #        tickcolor="#333333",
        ),
        yaxis=dict(
            title="Monthly rate",
            side="left",
            #            gridcolor="#cccccc",
            #            linecolor="#555555",  # Dark gray for the secondary y-axis line
            #            linewidth=2,
            #        tickcolor="#555555"
        ),
        yaxis2=dict(
            title="Annual rate",
            overlaying="y",
            side="right",
            showgrid=False,
            #            gridcolor="#cccccc",
            #            linecolor="#333333",  # Dark gray for the secondary y-axis line
            #            linewidth=2,
        ),
        legend=dict(
            orientation="h",  # Horizontal orientation
            yanchor="top",  # Anchor at the top of the legend box
            y=-0.1,  # Position it below the plot (adjust as needed)
            xanchor="center",  # Center align the legend
            x=0.5,  # Place at the center of the plot horizontally
        ),
        #        plot_bgcolor="#ffffff",  # Light gray background for the plot area #f9f9f9
        #        paper_bgcolor="#ffffff", # Slightly darker gray for the entire figure
    )

    # Show the figure
    #    figE_bar_line.show()

    # Store the figure in the dictionary
    figures[cat] = figE_bar_line

# Access the first figure (e.g., for "Exports")
exports_figure = figures["Exports"]
imports_figure = figures["Imports"]
exports_figure.show()
imports_figure.show()
```


```{python}
# # import pandas as pd
# from tabulate import tabulate

# # Sample larger DataFrame
# data1 = {
#     "Category": [
#         "Fruits",
#         "Fruits",
#         "Fruits",
#         "Vegetables",
#         "Vegetables",
#         "Vegetables",
#     ],
#     "Subcategory": ["Citrus", "Citrus", "Berries", "Root", "Leafy", "Root"],
#     "Item": ["Orange", "Lemon", "Strawberry", "Carrot", "Spinach", "Potato"],
#     "Value": [10, 15, 20, 8, 12, 5],
# }
# df = pd.DataFrame(data1)

# # Initialize an empty DataFrame for cascading table
# cascading_table = pd.DataFrame(columns=["Category", "Subcategory", "Item", "Value"])

# # Slice data by Category and append it incrementally
# for category in df["Category"].unique():
#     # Add a row for the category
#     category_row = pd.DataFrame(
#         [{"Category": category, "Subcategory": "", "Item": "", "Value": ""}]
#     )
#     cascading_table = pd.concat([cascading_table, category_row], ignore_index=True)

#     # Filter data for the current category
#     category_data = df[df["Category"] == category]

#     for subcategory in category_data["Subcategory"].unique():
#         # Filter data for the current subcategory
#         subcategory_data = category_data[category_data["Subcategory"] == subcategory]

#         for _, row in subcategory_data.iterrows():
#             subcategory_row = pd.DataFrame(
#                 [
#                     {
#                         "Category": "",
#                         "Subcategory": f"  {subcategory}",  # Indent subcategory
#                         "Item": f"    {row['Item']}",  # Indent item
#                         "Value": row["Value"],
#                     }
#                 ]
#             )
#             cascading_table = pd.concat(
#                 [cascading_table, subcategory_row], ignore_index=True
#             )

# # Print the cascading table
# print(tabulate(cascading_table, headers="keys", tablefmt="grid"))
    
```

```{python}
tabE = data.query('H04 == "Exports"')
tabE.loc[tabE["H03"].str.contains('UVI45600')]

tabE.iloc[25,2] == 'UVI45600'
# Initialize an empty DataFrame
t_table = pd.DataFrame()

la = 0
lb = 1
lc = 1
# Iterate over the rows
for index, row in tabE.iterrows():
    if row["H03"] == f"UVI4{la}000":
        # Select specific columns and convert to a single-row DataFrame
        col_sel = row[["H03", "H05", "H02", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        # print(f"Index: {index}, H03: {row['H03']}, la: {la}, lb: {lb}, lc: {lc}")
        # Concatenate the single-row DataFrame to the existing DataFrame
        t_table = pd.concat([t_table, col_sel], ignore_index=True)

        # Increment `la` for the next iteration
        la += 1

        # Reset `lb` to 1 for the new `la-1`
        lb = 1

    elif row["H03"] == f"UVI4{la-1}{lb}00":

        col_sel1 = row[["H03", "H02", "H05", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        print(f"Index: {index}, H03: {row['H03']}, la: {la}, lb: {lb}, lc: {lc}")
        # Rename to ensure the second-level column selection order is maintained
        col_sel1 = col_sel1.rename(columns={"H02": "H05", "H05": "H02"})
        print(f"Matched: {row['H03']} with UVI4{la-1}{lb}00")
        t_table = pd.concat([t_table, col_sel1], ignore_index=True)

        # Increment `lb` for the next iteration
        lb += 1
        # Reset `lc` to 1 for the new `lb-1`
        lc = 1

    elif row["H03"] == f"UVI4{la-1}{lb-1}{lc}0":
        
        col_sel2 = row[["H03", "H02", "H04", "H05", "MO012022", "MO122022", "MO012023"]].to_frame().T
        print(f"Matched: {row['H03']} with UVI4{la-1}{lb-1}{lc}0")
        col_sel2 = col_sel2.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})
        
        t_table = pd.concat([t_table, col_sel2], ignore_index=True)

        # Increment `lc` for the next iteration
        lc += 1
    elif row["H03"] == "UVI45600":
        col_sel3 = row[["H03", "H02", "H05", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        
        col_sel3 = col_sel3.rename(columns={"H02": "H05", "H05": "H02"})
        
        t_table = pd.concat([t_table, col_sel3], ignore_index=True)

t_table
```

```{python}
replacements = {"Export and Import Unit Value Indices": "", "Exports": ""}

t_table["H05"] = t_table["H05"].replace(replacements)
t_table["H02"] = t_table["H02"].replace(replacements)
t_table["H04"] = t_table["H04"].replace(replacements)

t_table = t_table.rename(
    columns={
        # "H05": "",
        "H02": "Product",
        # "H04": "",
        # "H18": "Weight",
        "MO012022": "Jan 2022",
        "MO122022": "Dec 2022",
        "MO012023": "Jan 2023",
    }
).dropna()
t_table
```

```{python}
# tabE = data.query('H04 == "Exports"')
# tab1 = tabE.loc[
#     (
#         (tabE["H05"] == "All items")
#         | (tabE["H05"] == "Agriculture")
#         | (tabE["H05"] == "Ores and minerals")
#     ),
#     ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
# ]

# tab2 = tabE.loc[
#     (
#         (tabE["H05"] == "Coal")
#         | (tabE["H05"] == "Metal ores")
#     ),
#     ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
# ]
# tab2 = tab2.rename(columns={"H02": "H05", "H05": "H02"}) # This ensures that pd.concat does not re-order the columns

# tab3 = tabE.loc[
#     (
#         (tabE["H05"] == "Iron ores and concentrates")
#         | (tabE["H05"] == "Non-ferrous metal ores and concentrates")
#     ),
#     ["H02", "H04", "H05", "MO012022", "MO122022", "MO012023"],
# ]
# tab3 = tab3.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})

# tab4 = tabE.loc[
#     (
#         (tabE["H05"] == "Beverages")
#         | (tabE["H05"] == "Other transportable goods, except metal products, machinery and equipment")
#     ),
#     ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
# ]

# tab5 = tabE.loc[
#     (
#         (tabE["H05"] == "Coke oven and refined petroleum products")
#         | (tabE["H05"] == "Basic chemicals")
#         | (tabE["H05"] == "Other chemical products")
#         | (tabE["H05"] == "Rubber and plastic products")
#     ),
#     ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
# ]
# tab5 = tab5.rename(columns={"H02": "H05", "H05": "H02"})

# tab6 = tabE.loc[
#     (
#         (tabE["H05"] == "Metal products, machinery and equipment")
#     ),
#     ["H05", "H02", "H04", "MO012022", "MO122022", "MO012023"],
# ]

# tab7 = tabE.loc[
#     (
#         (tabE["H05"] == "Basic metals")
#     ),
#     ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
# ]
# tab7 = tab7.rename(columns={"H02": "H05", "H05": "H02"})

# tab8 = tabE.loc[
#     (
#         (tabE["H05"] == "Basic iron and steel")
#         | (tabE["H05"] == "Productsof iron and steel")
#         | (tabE["H05"] == "Basic precious metals and metals clad with precious metals")
#         | (tabE["H05"] == "Other semi-finished metal products")
#     ),
#     ["H02", "H04", "H05", "MO012022", "MO122022", "MO012023"],
# ]
# tab8 = tab8.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})


# tab9 = tabE.loc[
#     (
#         (tabE["H05"] == "Fabricated metal products, except machinery and equipment")
#         | (tabE["H05"] == "General purpose machinery")
#         | (tabE["H05"] == "Special-purpose machinery")
#         | (tabE["H05"] == "Transport equipment")
#         | (tabE["H05"] == "Motor vehicles")
#         | (tabE["H05"] == "Other  machinery and equipment") # double spacing between Other  machinery inherited from raw data
#     ),
#     ["H02", "H05", "H04", "MO012022", "MO122022", "MO012023"],
# ]
# tab9 = tab9.rename(columns={"H02": "H05", "H05": "H02"})

# tables = [tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9]

# # Initialize an empty DataFrame for cascading table
# cascad_table = pd.DataFrame()

# for table in tables:
#     cascad_table = pd.concat([cascad_table, table], ignore_index=True)

# cascad_table

# replacements = {"Export and Import Unit Value Indices": "", "Exports": ""}

# cascad_table["H05"] = cascad_table["H05"].replace(replacements)
# cascad_table["H02"] = cascad_table["H02"].replace(replacements)
# cascad_table["H04"] = cascad_table["H04"].replace(replacements)

# cascad_table = cascad_table.rename(
#     columns={
#         # "H05": "",
#         "H02": "Product",
#         # "H04": "",
#         # "H18": "Weight",
#         "MO012022": "Jan 2022",
#         "MO122022": "Dec 2022",
#         "MO012023": "Jan 2023",
#     }
# )

# cascad_table['Jan 2023 vs. Dec 2022'] = (((cascad_table['Jan 2023'] - cascad_table['Dec 2022']) / cascad_table['Dec 2022']) * 100).round(2).astype(str) + "%"

# cascad_table['Jan 2023 vs. Jan 2022'] = (((cascad_table['Jan 2023'] - cascad_table['Jan 2022']) / cascad_table['Jan 2022']) * 100).round(2).astype(str) + "%"

# cascad_table
```


```{python}
t_table['Jan 2023 vs. Dec 2022'] = (((t_table['Jan 2023'] - t_table['Dec 2022']) / t_table['Dec 2022']) * 100).round(2) #.astype(str) + "%"

t_table['Jan 2023 vs. Jan 2022'] = (((t_table['Jan 2023'] - t_table['Jan 2022']) / t_table['Jan 2022']) * 100).round(2) #.astype(str) + "%"

t_table.shape
# cascad_table.iloc[1 :,0:3].value_counts(normalize=True)

```

Calculating the weights

```{python}

# Helper function to calculate subtotal for a list of product categories
def calculate_subtotal(df, categories):
    return (
        df.query("H05 in @categories")
        .groupby("H05")["Amount"]
        .sum()
        .squeeze()
    )

# Helper function to calculate weights
def calc_weight(value, total):
    return ((value / total) * 100).round(1)

# Product group mappings
product_groups = {
    "Agriculture": ["Agriculture"],
    "Coal": ["Coal"],
    "Metal Ores": [
        "Iron ores and concentrates",
        "Non-ferrous metal ores and concentrates",
    ],
    "Beverages": ["Beverages"],
    "Other Transportable": [
        "Coke oven and refined petroleum products",
        "Basic chemicals",
        "Other chemical products",
        "Rubber and plastic products",
    ],
    "Basic Metals": [
        "Basic iron and steel",
        "Productsof iron and steel",
        "Basic precious metals and metals clad with precious metals",
        "Other semi-finished metal products",
    ],
    "Other Metal Products": [
        "Fabricated metal products, except machinery and equipment",
        "General purpose machinery",
        "Special-purpose machinery",
        "Transport equipment",
        "Other  machinery and equipment",
    ],
}

# Calculate subtotals for each group
subtotals = {group: calculate_subtotal(exports_weight, categories) for group, categories in product_groups.items()}

# Calculate totals for combined groups
total_agri = subtotals["Agriculture"]
total_coal = subtotals["Coal"]
total_metal_ores = subtotals["Metal Ores"].sum()
iron_ores = subtotals["Metal Ores"]["Iron ores and concentrates"]
non_ferrous = subtotals["Metal Ores"]["Non-ferrous metal ores and concentrates"]
total_ores = total_coal + total_metal_ores
total_bev = subtotals["Beverages"]
total_transportable = subtotals["Other Transportable"].sum()
total_basic_metals = subtotals["Basic Metals"].sum()
total_other_metals = subtotals["Other Metal Products"].sum()
total_metal_products = total_basic_metals + total_other_metals

subtotals_df = pd.DataFrame(list(subtotals.items()), columns=["H05", "Weight"])

# Calculate total exports
total_exports_proper = (
    total_agri + total_ores + total_bev + total_transportable + total_metal_products
)

# Calculate weights
weights = {group: calc_weight(total, total_exports_proper) for group, total in subtotals.items()}

# Individual weights
weights.update({
    "Iron Ores": calc_weight(iron_ores, total_exports_proper),
    "Non-Ferrous Ores": calc_weight(non_ferrous, total_exports_proper),
    "All Items": sum(weights.values()),  # Sum of all weights
})

# Display results
print("Weights:")
for group, weight in weights.items():
    print(f"{group}: {weight}%")

[weights]
weights[weights.keys]

weights_df = pd.DataFrame.from_dict(weights, orient="index", columns=["Weight"]).reset_index()
weights_df.rename(columns={"index": "H05"}, inplace=True)

weights_df = pd.DataFrame(list(weights.items()), columns=["H05", "Weight"])

#
```

```{python}
exports_weight = (
    clean_data.query('H04 == "Exports"')
    .query('datetime >= "2022-01-01" & datetime <= "2023-01-02"')
    .dropna()
)

test = exports_weight.groupby(["H03", "H05"]).agg(sum_ind = ("Amount", "sum")).reset_index()

la = 1
lb = 1
lc = 1

hs_total = 0

# Iterate over the rows
for index, row in test.iterrows():
    if row["H03"] == f"UVI4{lc}000":
        # Select specific columns and convert to a single-row DataFrame
        col_sel = (
            row[["sum_ind"]]
            # .to_frame()
            # .T
        )
        print(f"Matched: {row['H03']} with UVI4{la}000")
        # Concatenate the single-row DataFrame to the existing DataFrame
        hs_total = hs_total + col_sel

        # Increment `la` for the next iteration
        la += 1
hs_total
        # Reset `lb` to 1 for the new `la-1`
        # lb = 1

for index, row in tabE.iterrows():
    match row["H03"]:
        case f"UVI4{la}000":
            col_sel = (
                row[["H03", "H02", "H04", "H05", "MO012022", "MO122022", "MO012023"]]
                .to_frame()
                .T
            )
            t_table = pd.concat([t_table, col_sel], ignore_index=True)
            la += 1

        case f"UVI4{la-1}{lb}00":
            col_sel = (
                row[["H03", "H02", "H04", "H05", "MO012022", "MO122022", "MO012023"]]
                .to_frame()
                .T
            )
            t_table = pd.concat([t_table, col_sel], ignore_index=True)
            lb += 1


exports_weight = (
    clean_data.query('H04 == "Exports"')
    .query('datetime >= "2022-01-01" & datetime <= "2023-01-02"')
    .dropna()
)

# Total agriculture
total_agri = (
    exports_weight.query('H05 == "Agriculture"')
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total coal
total_coal = (
    exports_weight.query('H05 == "Coal"').groupby("H05")["Amount"].sum().squeeze()
)

# Subtotal for metal ores
sub_metal_ores = (
    exports_weight.query(
        'H05 == "Iron ores and concentrates" | H05 == "Non-ferrous metal ores and concentrates"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

non_ferrous = sub_metal_ores["Non-ferrous metal ores and concentrates"]
iron_ores = sub_metal_ores["Iron ores and concentrates"]

total_metal_ores = sub_metal_ores.sum()

# Ores and minerals
total_ores = total_coal + total_metal_ores

# Total beverages
total_bev = (
    exports_weight.query('H05 == "Beverages"').groupby("H05")["Amount"].sum().squeeze()
)

# Subtotal for other transportable
sub_transportable = (
    exports_weight.query(
        'H05 == "Coke oven and refined petroleum products" | H05 == "Basic chemicals" | H05 == "Other chemical products" | H05 == "Rubber and plastic products"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total for other transportable
total_transportable = sub_transportable.sum()

# Subtotal for basic metals
sub_basic_metals = (
    exports_weight.query(
        'H05 == "Basic iron and steel" | H05 == "Productsof iron and steel" | H05 == "Basic precious metals and metals clad with precious metals" | H05 == "Other semi-finished metal products"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

# Total for basic metals
total_basic_metals = sub_basic_metals.sum()

# Subtotal for metal products excluding basic metals
sub_other_metals = (
    exports_weight.query(
        'H05 == "Fabricated metal products, except machinery and equipment" | H05 == "General purpose machinery" | H05 == "Special-purpose machinery" | H05 == "Transport equipment" | H05 == "Other  machinery and equipment"'
    )
    .groupby("H05")["Amount"]
    .sum()
    .squeeze()
)

total_other_metals = sub_other_metals.sum()  # not on the table

total_metal_products = total_basic_metals + total_other_metals

# total exports from commodity groups
total_exports_proper = (
    total_agri + total_ores + total_bev + total_transportable + total_metal_products
)


# The weights for each commodity group
def calc_weight(comd):
    return ((comd / total_exports_proper) * 100).round(1)


weight_agri = calc_weight(total_agri)

weight_ores = calc_weight(total_ores)

weight_coal = calc_weight(total_coal)

weight_metal_ores = calc_weight(total_metal_ores)


weight_iron_ores = calc_weight(iron_ores)

weight_non_ferrous = calc_weight(non_ferrous)


weight_bev = calc_weight(total_bev)

weight_transportable = calc_weight(total_transportable)

weight_basic_chem = calc_weight(sub_transportable[0])
weight_coke = calc_weight(sub_transportable[1])
weight_other_chem = calc_weight(sub_transportable[2])
weight_rubber = calc_weight(sub_transportable[3])


weight_metal_products = calc_weight(total_metal_products)

weight_basic_metals = calc_weight(total_basic_metals)

weight_basic_iron = calc_weight(sub_basic_metals[0])
weight_precious_metals = calc_weight(sub_basic_metals[1])
weight_semi_finished = calc_weight(sub_basic_metals[2])
weight_product_iron = calc_weight(sub_basic_metals[3])


weight_fabric_metal = calc_weight(sub_other_metals[0])
weight_gen_purpose = calc_weight(sub_other_metals[1])

weight_machine_equip = calc_weight(sub_other_metals[2])
weight_spec_purpose = calc_weight(sub_other_metals[3])
weight_transport = calc_weight(sub_other_metals[4])
weight_motor = weight_transport

weight_all_items = (
    weight_agri
    + weight_ores
    + weight_bev
    + weight_transportable
    + weight_metal_products
)

h03 = t_table['H03']
tb_data = {
    "H03":h03,
    "Weight": [
        weight_all_items,
        weight_agri,
        weight_bev,
        weight_ores,
        weight_coal,
        weight_metal_ores,
        weight_iron_ores,
        weight_non_ferrous,
        weight_transportable,
        weight_coke,
        weight_basic_chem,
        weight_other_chem,
        weight_rubber,
        weight_metal_products,
        weight_basic_metals,
        weight_basic_iron,
        weight_product_iron,
        weight_precious_metals,
        weight_semi_finished,
        weight_fabric_metal,
        weight_gen_purpose,
        weight_spec_purpose,
        weight_transport,
        weight_motor,
        weight_machine_equip,
    ],
}

df_weights = pd.DataFrame(tb_data)

tab1_exports = pd.merge(t_table,df_weights, on='H03', how='left')

# Initialize a counter for the replacement values
counter = 1

# Iterate over the rows and update empty strings
for index, row in t_table.iterrows():
    if row["Product"] == "":
        t_table.at[index, "Product"] = f"a{counter}"
        counter += 1  # Increment the counter for the next replacement
    
```

```{python}

# Filter and clean data
exports_weight = (
    clean_data.query('H04 == "Exports"')
    .query('datetime >= "2022-01-01" & datetime <= "2023-01-02"')
    .dropna()
)

# Helper function to calculate subtotal for given H03 values
def calculate_subtotal(df, h03_values):
    return (
        df.query("H03 in @h03_values")
        .groupby("H03")["Amount"]
        .sum()
        .squeeze()
    )

# Helper function to calculate weights
def calc_weight(value, total):
    return ((value / total) * 100).round(1)

# Define product groups using H03 codes
product_groups_h03 = {
    "Agriculture": ["UVI41000"],
    "Coal": ["UVI43100"],
    "Metal Ores": ["UVI43210", "UVI4320"],
    "Beverages": ["UVI42000"],
    "Other Transportable": [
        "UVI44100",
        "UVI44200",
        "UVI44300",
        "UVI44500",
    ],
    "Basic Metals": [
        "UVI45110",
        "UVI45120",
        "UVI45130",
        "UVI45140",
    ],
    "Other Metal Products": [
        "UVI45600",
        "UVI45200",
        "UVI45300",
        "UVI45400",
        "UVI45410",
        "UVI45500",
    ],
}

# Calculate subtotals for each group
subtotals = {
    group: calculate_subtotal(exports_weight, h03_codes)
    for group, h03_codes in product_groups_h03.items()
}

# Specific subtotals
# iron_ores = subtotals["Metal Ores"]["UVI43210"]
# non_ferrous = subtotals["Metal Ores"]["UVI43220"]
total_metal_ores = subtotals["Metal Ores"].sum()
total_ores = subtotals["Coal"] + total_metal_ores
total_transportable = subtotals["Other Transportable"].sum()
total_basic_metals = subtotals["Basic Metals"].sum()
total_other_metals = subtotals["Other Metal Products"].sum()
total_metal_products = total_basic_metals + total_other_metals

# Total exports
total_exports_proper = (
    subtotals["Agriculture"] + total_ores + subtotals["Beverages"] +
    total_transportable + total_metal_products
)

# Calculate weights for all groups
weights = {group: calc_weight(total, total_exports_proper) for group, total in subtotals.items()}

# Add individual weights for subcategories
weights.update({
    "Iron Ores": calc_weight(iron_ores, total_exports_proper),
    "Non-Ferrous Ores": calc_weight(non_ferrous, total_exports_proper),
    "All Items": sum(weights.values()),  # Sum of all weights
})

# Create the DataFrame for weights
h03 = t_table["H03"]
tb_data = {
    "H03": h03,
    "Weight": [
        weights.get("All Items", 0),
        weights.get("Agriculture", 0),
        weights.get("Beverages", 0),
        weights.get("Metal Ores", 0),
        weights.get("Coal", 0),
        weights.get("Iron Ores", 0),
        weights.get("Non-Ferrous Ores", 0),
        weights.get("Other Transportable", 0),
        weights.get("Basic Metals", 0),
        weights.get("Other Metal Products", 0),
    ],
}

df_weights = pd.DataFrame(tb_data)

# Merge weights with t_table
tab1_exports = pd.merge(t_table, df_weights, on="H03", how="left")

# Display the resulting table
print(tab1_exports)


```

```{python}
tab1_exports = pd.merge(t_table,df_weights, on='H03', how='left')
tab1_exports.shape
col_list = list(tab1_exports.columns)

col_list.insert(
    4, col_list.pop(9)
)  # Pop the 10th column (index 9) and insert at the 5th
col_list

tab1_exports = tab1_exports[col_list]

# Initialize a counter for the replacement values
countr = 1

# Iterate over the rows and update empty strings
for index, row in tab1_exports.iterrows():
    if row["Product"] == f"a{countr}":
        tab1_exports.at[index, "Product"] = ""
        countr += 1  # Increment the counter for the next replacement

tab1_exports = tab1_exports.rename(
    columns={
        "H05": "",
        "H04": "",
    }
)

tab1_exports
```


```{python}
clean_data.loc[clean_data['H03'].str.contains('UVI43')].query(
    'datetime >= "2022-01-01" & datetime <= "2023-01-01"'
)
```


```{python}
tabI = data.query('H04 == "Imports"')
# Initialize an empty DataFrame
t_table1 = pd.DataFrame()

la = 0
lb = 1
lc = 1
# Iterate over the rows
for index, row in tabI.iterrows():
    if row["H03"] == f"UVI5{la}000":
        # Select specific columns and convert to a single-row DataFrame
        col_sel = row[["H03", "H05", "H02", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        # print(f"Index: {index}, H03: {row['H03']}, la: {la}, lb: {lb}, lc: {lc}")
        # Concatenate the single-row DataFrame to the existing DataFrame
        t_table = pd.concat([t_table1, col_sel], ignore_index=True)

        # Increment `la` for the next iteration
        la += 1

        # Reset `lb` to 1 for the new `la-1`
        lb = 1

    elif row["H03"] == f"UVI5{la-1}{lb}00":

        col_sel1 = row[["H03", "H02", "H05", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        print(f"Index: {index}, H03: {row['H03']}, la: {la}, lb: {lb}, lc: {lc}")
        # Rename to ensure the second-level column selection order is maintained
        col_sel1 = col_sel1.rename(columns={"H02": "H05", "H05": "H02"})
        print(f"Matched: {row['H03']} with UVI4{la-1}{lb}00")
        t_table = pd.concat([t_table1, col_sel1], ignore_index=True)

        # Increment `lb` for the next iteration
        lb += 1
        # Reset `lc` to 1 for the new `lb-1`
        lc = 1

    elif row["H03"] == f"UVI5{la-1}{lb-1}{lc}0":
        
        col_sel2 = row[["H03", "H02", "H04", "H05", "MO012022", "MO122022", "MO012023"]].to_frame().T
        print(f"Matched: {row['H03']} with UVI5{la-1}{lb-1}{lc}0")
        col_sel2 = col_sel2.rename(columns={"H02": "H05", "H04": "H02", "H05": "H04"})
        
        t_table = pd.concat([t_table1, col_sel2], ignore_index=True)

        # Increment `lc` for the next iteration
        lc += 1
    # elif row["H03"] == "UVI45600":
    #     col_sel3 = row[["H03", "H02", "H05", "H04", "MO012022", "MO122022", "MO012023"]].to_frame().T
        
    #     col_sel3 = col_sel3.rename(columns={"H02": "H05", "H05": "H02"})
        
    #     t_table = pd.concat([t_table, col_sel3], ignore_index=True)

t_table1
```


```{python}
replacements = {"Export and Import Unit Value Indices": "", "Exports": ""}

t_table1["H05"] = t_table1["H05"].replace(replacements)
t_table1["H02"] = t_table1["H02"].replace(replacements)
t_table1["H04"] = t_table1["H04"].replace(replacements)

t_table1 = t_table1.rename(
    columns={
        # "H05": "",
        "H02": "Product",
        # "H04": "",
        # "H18": "Weight",
        "MO012022": "Jan 2022",
        "MO122022": "Dec 2022",
        "MO012023": "Jan 2023",
    }
).dropna()
t_table1

```